{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL\n",
    "import glob\n",
    "import time\n",
    "import imageio\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Loading Zip File\n",
    "zip_path = r'C:\\Users\\anshu\\OneDrive\\Desktop\\dataset.zip'\n",
    "extract_path = r'C:\\Users\\anshu\\OneDrive\\Desktop\\extracted_data'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# Defining Function & Loading Images\n",
    "def load_images(image_folder, image_files):\n",
    "    images=[]\n",
    "    for file_name in image_files:\n",
    "        if file_name.endswith(('.jpg','.jpeg')):\n",
    "            img_path=os.path.join(image_folder, file_name)\n",
    "            img= Image.open(img_path).convert('RGB')\n",
    "            images.append(img)\n",
    "    return images    \n",
    "\n",
    "image_folder = extract_path\n",
    "image_files = [file for file in os.listdir(image_folder) if file.lower().endswith(('jpg', 'jpeg'))]\n",
    "images = load_images(image_folder, image_files)   \n",
    "\n",
    "# Histogram Equalization\n",
    "def clahe_equalization(img):\n",
    "    img_lab = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2Lab)\n",
    "    l, a, b = cv2.split(img_lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    l_clahe = clahe.apply(l)\n",
    "    img_lab = cv2.merge((l_clahe, a, b))\n",
    "    img_equalized = cv2.cvtColor(img_lab, cv2.COLOR_Lab2RGB)\n",
    "    return Image.fromarray(img_equalized)\n",
    "\n",
    "equalized_images = [clahe_equalization(img) for img in images]\n",
    "\n",
    "# Resizing & Normalizing\n",
    "def process(equalized_images, size=(150, 212)):\n",
    "    processed_images = []\n",
    "    for img in equalized_images:\n",
    "        img_resized = img.resize(size)\n",
    "        if img_resized.mode != 'RGB':\n",
    "            img_resized = img_resized.convert('RGB')\n",
    "        img_array = np.array(img_resized) / 127.5 - 1.0\n",
    "        processed_images.append(img_array)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "resized_images = process(equalized_images)\n",
    "\n",
    "# Augmentation\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "aug_images = []\n",
    "for img in resized_images:\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    aug_iter = data_generator.flow(img)\n",
    "    for _ in range(2):  # Number of augmentations per image\n",
    "        aug_image = next(aug_iter)\n",
    "        aug_images.append(aug_image[0])\n",
    "\n",
    "# Training Set allocation\n",
    "train_images = np.array([np.array(img) for img in aug_images])\n",
    "BUFFER_SIZE = 20\n",
    "BATCH_SIZE = 10\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "# Defining Generator Model\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(53*38*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((53, 38, 256)))\n",
    "    assert model.output_shape == (None, 53, 38, 256)\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 106, 76, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 212, 152, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 212, 152, 3)\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "# Convert the EagerTensor to a NumPy array before using astype\n",
    "generated_image_np = generated_image[0].numpy()\n",
    "generated_image_np = (generated_image_np * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "# Defining Discriminator Model\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[212, 152, 3]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Defining Discriminator Loss\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "# Defining Generator Loss\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "# Optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Adding Chekpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "# Setting Noise & number of EPOCHS\n",
    "EPOCHS = 300\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "# Feedback Mechanism (Real and Fake Image differentiation)\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# Generating and Saving Images\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow((predictions[i, :, :, :].numpy() * 127.5 + 127.5).astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n",
    "\n",
    "# Training the Model\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, seed)\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)\n",
    "\n",
    "train(train_dataset, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
